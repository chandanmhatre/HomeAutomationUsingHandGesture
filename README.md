This project employs a Pickle model to fit a hand landmarks dataset obtained from MediaPipe implementation. It involves data collection, implementing the MediaPipe hand tracking pipeline with machine learning techniques, and storing data in a Pickle model. The pipeline includes a hand landmark model and a finger detector using a Convolutional Neural Network (CNN), achieving high accuracy in detecting 21 hand-knuckle coordinates. Data collection runs the MediaPipe hand tracking graph to obtain coordinates for each frame, stored in a pickle model ensuring no need for retraining the machine learning model each time. Streamlit is used for presenting OpenCV frames and deploying machine learning modules. The system triggers IoT devices, specifically a Raspberry Pi, using Firebase's real-time dataset and queries for automation. Known gesture data is compared with real-time detected gestures, triggering the IoT device to control electric appliances.
